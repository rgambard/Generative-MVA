{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fb87f02-c727-4b64-8e16-118800d61da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from unet import ResidualUNet, Denoiser\n",
    "from utils import save_image, dotdict\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "#sigmas = 3*torch.pow(torch.ones(50)*0.9,torch.arange(50))\n",
    "betat = torch.linspace(1e-4,0.02,1000)\n",
    "alphat = 1-betat\n",
    "alphabart = [1]\n",
    "for alpha in alphat:\n",
    "    alphabart.append(alphabart[-1]*alpha)\n",
    "\n",
    "alphabart = torch.Tensor(alphabart[1:])\n",
    "#print(alphabart)\n",
    "\n",
    "\n",
    "def forward(data, model, alphasb_batch = None):\n",
    "    im = data\n",
    "\n",
    "    # parameters of the langevin dynamics steps\n",
    "    ind_randoms= torch.randint(0, alphat.shape[0], (data.shape[0],), device = data.device)\n",
    "    \n",
    "    noise_in = torch.randn_like(im)\n",
    "    if alphasb_batch is None:\n",
    "        alphasb_batch = alphabart[ind_randoms]\n",
    "\n",
    "        im_input = (torch.sqrt(1-alphasb_batch)[:,None,None,None]*noise_in+torch.sqrt(alphasb_batch)[:,None,None,None]*im)\n",
    "    else :\n",
    "        im_input = im\n",
    "    # we append the sigmas to the model input as a new dimension of the image\n",
    "    features_sigma = torch.sin(ind_randoms[:,None,None,None]/1000*(torch.arange(im.shape[2], device = im.device)[None,None,:,None]*20+200*torch.arange(im.shape[3], device = im.device)[None,None,None,:]))/0.70 # we encode the sigmas into sinosiudals encodings \n",
    "    #mod_input = torch.cat((im_input_norm, features_sigma, features_mean, features_std), dim=1)\n",
    "    mod_input = torch.cat((im_input, features_sigma), dim=1)\n",
    "    #(noise_in+im)/sqrt(2) = pred\n",
    "    #pred-torch.sqrt(1-alphasb_batch)*im_input=\n",
    "    #noise+  \n",
    "    pred_eps = model(mod_input)\n",
    "    score = -pred_eps/torch.sqrt(1-alphasb_batch)[:,None,None,None]\n",
    "    # corrected image \n",
    "    im_corrected = (im_input-torch.sqrt(1-alphasb_batch)[:,None,None,None]*pred_eps)/torch.sqrt(alphasb_batch)[:,None,None,None]\n",
    "\n",
    "    square_norm = torch.sum((pred_eps-noise_in)**2,(1,2,3)) # square norm of loss per image\n",
    "    loss = square_norm.sum()\n",
    "    return loss, im_input, im_corrected, pred_eps, score\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "     \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, im_input, im_corrected, pred_eps, score= forward(data, model)\n",
    "\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx+1) % args.log_interval  == 0:\n",
    "            running_loss = running_loss/(args.log_interval*args.batch_size)\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), running_loss))\n",
    "            running_loss = 0\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "nid= \"vnoise\"\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    ctime = time.time()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            im = data\n",
    "            loss, im_input, corr, pred_eps, score= forward(data, model)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set {:.4f} Average loss: {:.4f} \\n'.format(time.time()-ctime,test_loss))\n",
    "    orig = im\n",
    "    noisy = im_input\n",
    "    save_image(noisy[:10],\"im/noisy.jpg\")\n",
    "    save_image(corr[:10],\"im/corrected.jpg\")\n",
    "    save_image(orig[:10],\"im/originals.jpg\")\n",
    "    gen_shape = list(im.shape)\n",
    "    gen_shape[0] = 32\n",
    "    gen_im_sde = sample_sde(model, device, gen_shape)\n",
    "    save_image(gen_im_sde, \"im/generatedsde.jpg\")\n",
    "    gen_im_ddpm = sampleDDPM(model, device, gen_shape)\n",
    "    save_image(gen_im_ddpm, \"im/generatedddpm.jpg\")\n",
    "    gen_im_ode = sample_ode(model, device, gen_shape)\n",
    "    save_image(gen_im_ode, \"im/generatedode.jpg\")\n",
    "\n",
    "\n",
    "def sampleDDPM(model,device, im_shape):\n",
    "    print(\"generating images...\")\n",
    "    with torch.no_grad():\n",
    "        xt = torch.randn(im_shape, device = device)\n",
    "        for t in range(alphabart.shape[0]-1,1,-1):\n",
    "            zt = torch.randn_like(xt)\n",
    "            alpha = alphat[t]\n",
    "            beta = 1-alpha\n",
    "            alphasb_batch = torch.ones((xt.shape[0],), device=  device)*alphabart[t]\n",
    "            loss, im_input, im_corrected, pred_eps, score= forward(xt, model, alphasb_batch=alphasb_batch)\n",
    "            xt = 1/torch.sqrt(alpha)*(xt - beta/torch.sqrt((1-alphabart[t]))*pred_eps)+torch.sqrt((1-alphabart[t-1])/(1-alphabart[t])*beta)*zt\n",
    "            if t%100==0:\n",
    "                print(t, beta, torch.std(xt), torch.mean(xt))\n",
    "\n",
    "    print(\"images generated ! \")\n",
    "    return xt\n",
    "\n",
    "def sample_ode(self, device, im_shape):\n",
    "    with torch.no_grad():  # avoid backprop wrt model parameters\n",
    "        x = torch.randn(im_shape, device=device)\n",
    "        for t in range(alphabart.shape[0]-1,1,-1):\n",
    "            alpha_t = alphat[t]\n",
    "            beta_t = 1-alpha_t\n",
    "            alphasb_batch = torch.ones((x.shape[0],), device=  device)*alphabart[t]\n",
    "            loss, im_input, im_corrected, pred_eps, score = forward(x, model, alphasb_batch=alphasb_batch)\n",
    "            x = (2-torch.sqrt(1-beta_t))*x+1/2*beta_t*score\n",
    "    return x\n",
    "\n",
    "def sample_sde(self,device, im_shape):\n",
    "    with torch.no_grad():  # avoid backprop wrt model parameters\n",
    "        x = torch.randn(im_shape, device=device)\n",
    "        for t in range(alphabart.shape[0]-1,1,-1):\n",
    "            alpha_t = alphat[t]\n",
    "            beta_t = 1-alpha_t\n",
    "            alphasb_batch = torch.ones((x.shape[0],), device=  device)*alphabart[t]\n",
    "            loss, im_input, im_corrected, pred_eps, score = forward(x, model, alphasb_batch=alphasb_batch)\n",
    "            xp = (2-torch.sqrt(1-beta_t))*x+beta_t*score\n",
    "            noise = torch.randn_like(x)\n",
    "            x = xp + torch.sqrt(beta_t) * noise\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595ad68-8d9d-460a-bead-c3eded771cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [12736/60000 (21%)]\tLoss: 27.602430\n",
      "Train Epoch: 1 [25536/60000 (43%)]\tLoss: 27.222509\n",
      "Train Epoch: 1 [38336/60000 (64%)]\tLoss: 26.700051\n",
      "Train Epoch: 1 [51136/60000 (85%)]\tLoss: 26.800654\n",
      "Train Epoch: 2 [12736/60000 (21%)]\tLoss: 26.829519\n",
      "Train Epoch: 2 [25536/60000 (43%)]\tLoss: 26.642618\n",
      "Train Epoch: 2 [38336/60000 (64%)]\tLoss: 26.425340\n",
      "Train Epoch: 2 [51136/60000 (85%)]\tLoss: 27.334020\n",
      "Train Epoch: 3 [12736/60000 (21%)]\tLoss: 25.873827\n",
      "Train Epoch: 3 [25536/60000 (43%)]\tLoss: 26.554529\n",
      "Train Epoch: 3 [38336/60000 (64%)]\tLoss: 26.891091\n",
      "Train Epoch: 3 [51136/60000 (85%)]\tLoss: 25.910353\n",
      "\n",
      "Test set 4.2857 Average loss: 26.4491 \n",
      "\n",
      "generating images...\n",
      "900 tensor(0.0180) tensor(0.9902, device='cuda:0') tensor(-0.0077, device='cuda:0')\n",
      "800 tensor(0.0160) tensor(1.0005, device='cuda:0') tensor(-0.0285, device='cuda:0')\n",
      "700 tensor(0.0140) tensor(1.0099, device='cuda:0') tensor(-0.0398, device='cuda:0')\n",
      "600 tensor(0.0121) tensor(1.0432, device='cuda:0') tensor(-0.0411, device='cuda:0')\n",
      "500 tensor(0.0101) tensor(1.0658, device='cuda:0') tensor(-0.0388, device='cuda:0')\n",
      "400 tensor(0.0081) tensor(1.0770, device='cuda:0') tensor(-0.0276, device='cuda:0')\n",
      "300 tensor(0.0061) tensor(1.0583, device='cuda:0') tensor(-0.0162, device='cuda:0')\n",
      "200 tensor(0.0041) tensor(1.0042, device='cuda:0') tensor(-0.0288, device='cuda:0')\n",
      "100 tensor(0.0021) tensor(0.9210, device='cuda:0') tensor(-0.0550, device='cuda:0')\n",
      "images generated ! \n",
      "Train Epoch: 4 [12736/60000 (21%)]\tLoss: 26.094910\n",
      "Train Epoch: 4 [25536/60000 (43%)]\tLoss: 26.811219\n",
      "Train Epoch: 4 [38336/60000 (64%)]\tLoss: 26.873297\n",
      "Train Epoch: 4 [51136/60000 (85%)]\tLoss: 27.416432\n",
      "Train Epoch: 5 [12736/60000 (21%)]\tLoss: 26.172071\n",
      "Train Epoch: 5 [25536/60000 (43%)]\tLoss: 26.434418\n",
      "Train Epoch: 5 [38336/60000 (64%)]\tLoss: 26.197508\n",
      "Train Epoch: 5 [51136/60000 (85%)]\tLoss: 25.692806\n",
      "Train Epoch: 6 [12736/60000 (21%)]\tLoss: 25.786642\n",
      "Train Epoch: 6 [25536/60000 (43%)]\tLoss: 26.030603\n",
      "Train Epoch: 6 [38336/60000 (64%)]\tLoss: 25.924022\n",
      "Train Epoch: 6 [51136/60000 (85%)]\tLoss: 25.595559\n",
      "\n",
      "Test set 4.2845 Average loss: 25.5818 \n",
      "\n",
      "generating images...\n",
      "900 tensor(0.0180) tensor(1.0033, device='cuda:0') tensor(-0.0277, device='cuda:0')\n",
      "800 tensor(0.0160) tensor(1.0130, device='cuda:0') tensor(-0.0477, device='cuda:0')\n",
      "700 tensor(0.0140) tensor(1.0120, device='cuda:0') tensor(-0.0653, device='cuda:0')\n",
      "600 tensor(0.0121) tensor(1.0291, device='cuda:0') tensor(-0.0851, device='cuda:0')\n",
      "500 tensor(0.0101) tensor(1.0378, device='cuda:0') tensor(-0.0928, device='cuda:0')\n",
      "400 tensor(0.0081) tensor(1.0421, device='cuda:0') tensor(-0.1040, device='cuda:0')\n",
      "300 tensor(0.0061) tensor(1.0157, device='cuda:0') tensor(-0.1042, device='cuda:0')\n",
      "200 tensor(0.0041) tensor(0.9645, device='cuda:0') tensor(-0.1033, device='cuda:0')\n",
      "100 tensor(0.0021) tensor(0.8833, device='cuda:0') tensor(-0.1054, device='cuda:0')\n",
      "images generated ! \n",
      "Train Epoch: 7 [12736/60000 (21%)]\tLoss: 25.617201\n",
      "Train Epoch: 7 [25536/60000 (43%)]\tLoss: 25.740271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TEST = False# set to true to load model from disk and only generate to test langevin\n",
    "\n",
    "# Training settings\n",
    "args_dict = {'batch_size' : 64, 'test_batch_size' :64, 'epochs' :1000, 'lr' : 0.0002, 'gamma' : 0.995, 'no_cuda' :False, \n",
    "             'dry_run':False, 'seed': 1, 'log_interval' : 200, 'save_model' :True, 'only_test':False, 'model_path':\"models/denoisermnist.pt\", \n",
    "             'load_model_from_disk':True, 'dataset':\"MNIST\", 'test':False}\n",
    "args = dotdict(args_dict)\n",
    "#parser = argparse.ArgumentParser(description=\"A simple argument parser example.\")\n",
    "\n",
    "# Add arguments\n",
    "#parser.add_argument('--dataset', type=str, required=False, default = 'MNIST', help='Dataset can be one of MNIST, CIFAR, CELEBA')\n",
    "#parser.add_argument('--test', type= str, required = False, help='wether to only test a model, requires path to the testing weights')\n",
    "\n",
    "# Parse the arguments\n",
    "#margs = parser.parse_args()\n",
    "#args.dataset = margs.dataset\n",
    "#if margs.test is not None:\n",
    "#    print(\"TEST\")\n",
    "#    args.test = True\n",
    "#    print(args.test)\n",
    "#    args.model_path = margs.test\n",
    "\n",
    "if args.test:\n",
    "    print(\"TEST\")\n",
    "    args.load_model_from_disk = True\n",
    "    args.only_test = True\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "test_kwargs = {'batch_size': args.test_batch_size}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "dataset = args.dataset\n",
    "if dataset == \"CIFAR\":\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),#mean, std\n",
    "    transforms.RandomHorizontalFlip(p=0.5)\n",
    "    ])\n",
    "\n",
    "    dataset1 = datasets.CIFAR10(root='./data/cifar10', train=True, download=True, transform=transform)\n",
    "    dataset2 = datasets.CIFAR10(root='./data/cifar10', train=False, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "    model = Denoiser(4,3).to(device)\n",
    "elif dataset == \"CELEBA\":\n",
    "    transform = transforms.Compose([transforms.Resize((64,64)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                    std=[0.5, 0.5, 0.5])])\n",
    "    dataset1 = datasets.CelebA(\"./data/celeba\", split = 'train',download=False, transform=transform)\n",
    "    dataset2 = datasets.CelebA(\"./data/celeba\", split = 'test', download=False, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "    model = Denoiser(3,3).to(device)\n",
    "\n",
    "elif dataset==\"MNIST\":\n",
    "    # loading dataset\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Pad(2),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    dataset1 = datasets.MNIST('./data/mnist', train=True, download=True,\n",
    "    transform=transform)\n",
    "    dataset2 = datasets.MNIST('./data/mnist', train=False,\n",
    "    transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Denoiser(2,1).to(device)\n",
    "\n",
    "if args.load_model_from_disk:\n",
    "    model.load_state_dict(torch.load(args.model_path, weights_only= True))\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "\n",
    "alphabart= alphabart.to(device)\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    if not args.only_test:\n",
    "        train(args, model , device, train_loader, optimizer, epoch)\n",
    "        scheduler.step()\n",
    "        if args.save_model:\n",
    "            torch.save(model.state_dict(), args.model_path)\n",
    "    if epoch%3 == 0:\n",
    "        test(model,  device, test_loader)\n",
    "\n",
    "if args.save_model:\n",
    "    torch.save(model.state_dict(), args.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed50926-c934-4309-a360-592d2d580487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
